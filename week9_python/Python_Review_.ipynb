{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b88d80be-2e02-4fe9-81de-2b695ea1f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Review Project\n",
    "\n",
    "#Applying ML to Cancer Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e578d12f-f803-438f-b8de-089fd90f8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('C:/Users/ME/Documents/QBIO/sp24_cw/qbio_490_dgmarsha/analysis_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1869e65b-b311-4d8d-8641-05b1e848c38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cptac warning: Your version of cptac (1.1.2) is out-of-date. Latest is 1.5.13. Please run 'pip install --upgrade cptac' to update it. (C:\\Users\\ME\\anaconda3\\envs\\qbio_490_dgmarsha_v2\\Lib\\threading.py, line 1010)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cptac\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a8de577-521e-4ca2-af98-2d3432d752df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting dataframes...                  \r"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Sample_Tumor_Normal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\qbio_490_dgmarsha_v2\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sample_Tumor_Normal'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m cptac\u001b[38;5;241m.\u001b[39mdownload(dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCcrcc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m ccrcc \u001b[38;5;241m=\u001b[39m cptac\u001b[38;5;241m.\u001b[39mCcrcc()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qbio_490_dgmarsha_v2\\Lib\\site-packages\\cptac\\ccrcc.py:396\u001b[0m, in \u001b[0;36mCcrcc.__init__\u001b[1;34m(self, version, no_internet)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclinical\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m clinical\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m# Edit the format of the Patient_IDs to have normal samples marked the same way as in other datasets. Currently, normal patient IDs have an \"N\" prepended. We're going to erase that and append a \".N\"\u001b[39;00m\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m reformat_normal_patient_ids(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, existing_identifier\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m, existing_identifier_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m# Call function from dataframe_tools.py to sort all tables first by sample status, and then by the index\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m sort_all_rows(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qbio_490_dgmarsha_v2\\Lib\\site-packages\\cptac\\dataframe_tools.py:342\u001b[0m, in \u001b[0;36mreformat_normal_patient_ids\u001b[1;34m(data_dict, existing_identifier, existing_identifier_location)\u001b[0m\n\u001b[0;32m    338\u001b[0m existing_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(existing_identifier)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m existing_identifier_location \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    341\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatient_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatient_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[1;32m--> 342\u001b[0m         cond\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m~\u001b[39m((df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample_Tumor_Normal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormal\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatient_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr[\u001b[38;5;241m0\u001b[39m:existing_length] \u001b[38;5;241m==\u001b[39m existing_identifier))),\n\u001b[0;32m    343\u001b[0m         other\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatient_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr[existing_length:]\n\u001b[0;32m    344\u001b[0m     )\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m existing_identifier_location \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    347\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatient_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatient_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[0;32m    348\u001b[0m         cond\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m~\u001b[39m((df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample_Tumor_Normal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormal\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatient_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr[\u001b[38;5;241m-\u001b[39mexisting_length:] \u001b[38;5;241m==\u001b[39m existing_identifier))),\n\u001b[0;32m    349\u001b[0m         other\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatient_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr[:\u001b[38;5;241m-\u001b[39mexisting_length] \u001b[38;5;66;03m# Note that we use the negative of the existing length, since we're working with the end of the string\u001b[39;00m\n\u001b[0;32m    350\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qbio_490_dgmarsha_v2\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qbio_490_dgmarsha_v2\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sample_Tumor_Normal'"
     ]
    }
   ],
   "source": [
    "cptac.download(dataset=\"Ccrcc\")\n",
    "ccrcc = cptac.Ccrcc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df239cbb-441a-469f-b5f6-99cb7e6dde6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_data = ccrcc.get_dataframe(\"proteomics\",\"umich\")\n",
    "rna_data = ccrcc.get_dataframe(\"transcriptomics\",\"washu\")\n",
    "#bcm source doesn't work, I think the data is no longer hosted.\n",
    "clinical_data = ccrcc.get_clinical(\"mssm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2e038-6a6a-4053-9461-40e44430a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are comparing data from the clinical, protein, and RNA databases,\n",
    "#so we need to find the overlap between them. Any comparisons made would mean nothing if \n",
    "#they were across different patient's data.\n",
    "overlap_patients = np.intersect1d(protein_data.index,clinical_data.index)\n",
    "overlap_patients = np.intersect1d(overlap_patients,rna_data.index)\n",
    "\n",
    "overlap_protein_data = protein_data.loc[[index in overlap_patients for index in protein_data.index],:]\n",
    "overlap_rna_data = rna_data.loc[[index in overlap_patients for index in rna_data.index],:]\n",
    "overlap_clinical_data = clinical_data.loc[[index in overlap_patients for index in clinical_data.index],:]\n",
    "#These are the 110 patients shared across these three dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca5683-5fd7-4547-9355-3cd649489448",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(overlap_protein_data.index)==list(overlap_rna_data.index) and list(overlap_protein_data.index)==list(overlap_clinical_data.index))\n",
    "#Indices match.\n",
    "overlap_rna_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d2f1d2-3f60-4a38-a578-5f06628e5932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The transcriptomic data has many versions for each gene, which makes this difficult.\n",
    "#I want to make sure I don't find two versions of a gene are the most DE.\n",
    "kept_col=[False]*len(overlap_rna_data.columns)\n",
    "# def zeroes_count(array):\n",
    "#     count = np.where([i==0 for i in array],True, False)\n",
    "#     return sum(count)\n",
    "for i in range(len(overlap_rna_data.columns)):\n",
    "    if (np.sum(np.isnan(overlap_rna_data[overlap_rna_data.columns[i]]))==0 ):\n",
    "        # and zeroes_count(overlap_rna_data[overlap_rna_data.columns[i]]<)):\n",
    "        kept_col[i]=True\n",
    "overlap_rna_data=overlap_rna_data.loc[:,kept_col]\n",
    "        #No nulls in the column.\n",
    "        #I am removing nulls by cutting columns b/c I don't have many patients and I want to\n",
    "        #keep all of them. If there is one patient null across, that will ruin this.\n",
    "\n",
    "kept_col=[False]*len(overlap_protein_data.columns)\n",
    "# used_genes =set()\n",
    "for i in range(len(overlap_protein_data.columns)):\n",
    "    if (np.sum(np.isnan(overlap_protein_data[overlap_protein_data.columns[i]]))==0):\n",
    "        kept_col[i]=True\n",
    "overlap_protein_data=overlap_protein_data.loc[:,kept_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cfa5f-3771-4de6-94f1-ae1dea1cbfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The zeroes have to removed before log2 scaling.\n",
    "def adjust_zeroes(array):\n",
    "    x = np.where([i ==0 for i in array],0.00001,[i for i in array])\n",
    "    return x\n",
    "    for i in range(len(array)):\n",
    "        if(array[i]==0):\n",
    "            array[i] = 0.00001\n",
    "for col in overlap_rna_data.columns:\n",
    "    overlap_rna_data.loc[:,col]= adjust_zeroes(overlap_rna_data.loc[:,col])\n",
    "    overlap_rna_data.loc[:,col] = np.log2(overlap_rna_data.loc[:,col])\n",
    "    overlap_rna_data.loc[:,col] =np.where([-16.609640474436812==val for val in \n",
    "                                           overlap_rna_data.loc[:,col]],0,[val for val in \n",
    "                                                    overlap_rna_data.loc[:,col]])\n",
    "#I am putting them back in after though, so as to not have the large negative numbers \n",
    "#produced skew the DE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b16c9-08a7-488d-ad92-ab67e58d53fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostDiffGene = [[\"gene\",\"gene1\",\"gene1\",\"gene1\",\"gene1\"],[0,0,0,0,0]]\n",
    "for i in range(len(overlap_rna_data.columns)):\n",
    "    gene_III = overlap_rna_data.iloc[[x ==\"Stage III\" for x in overlap_clinical_data[\"tumor_stage_pathological\"]],i]\n",
    "    gene_I = overlap_rna_data.iloc[[x ==\"Stage I\" for x in overlap_clinical_data[\"tumor_stage_pathological\"]],i]\n",
    "    diff = np.abs(np.mean(gene_III)-np.mean(gene_I))\n",
    "    rank = 4\n",
    "    while(diff>mostDiffGene[1][rank]):\n",
    "        if(rank>0 and diff>mostDiffGene[1][rank-1]):\n",
    "            rank = rank-1;\n",
    "            continue\n",
    "        mostDiffGene[1][rank] = diff\n",
    "        mostDiffGene[0][rank] = overlap_rna_data.columns[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882860dd-84fa-4f79-840f-18b74496b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostDiffGene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20e9df-27c2-4e58-9b3d-7443648dac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostDiffProt = [[\"gene\",\"gene1\",\"gene1\",\"gene1\",\"gene1\"],[0,0,0,0,0]]\n",
    "for i in range(len(overlap_protein_data.columns)):\n",
    "    prot_III = overlap_protein_data.iloc[[x ==\"Stage III\" for x in overlap_clinical_data[\"tumor_stage_pathological\"]],i]\n",
    "    prot_I = overlap_protein_data.iloc[[x ==\"Stage I\" for x in overlap_clinical_data[\"tumor_stage_pathological\"]],i]\n",
    "    diff = np.abs(np.mean(prot_III)-np.mean(prot_I))\n",
    "    rank = 4\n",
    "    while(diff>mostDiffProt[1][rank]):\n",
    "        if(rank>0 and diff>mostDiffProt[1][rank-1]):\n",
    "            rank = rank-1;\n",
    "            continue\n",
    "        mostDiffProt[1][rank] = diff\n",
    "        mostDiffProt[0][rank] = overlap_protein_data.columns[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b29d0d63-9758-4783-ae3e-234e27b6c62c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mostDiffProt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#I'm going to omit the version of each gene and protein for simplicity.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     DEprot \u001b[38;5;241m=\u001b[39m \u001b[43mmostDiffProt\u001b[49m[\u001b[38;5;241m0\u001b[39m][i]\n\u001b[0;32m      5\u001b[0m     Features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProtein \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mDEprot[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m overlap_protein_data[DEprot]\n\u001b[0;32m      6\u001b[0m     DEgene \u001b[38;5;241m=\u001b[39m mostDiffGene[\u001b[38;5;241m0\u001b[39m][i]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mostDiffProt' is not defined"
     ]
    }
   ],
   "source": [
    "Features = pd.DataFrame()\n",
    "#I'm going to omit the version of each gene and protein for simplicity.\n",
    "for i in range(5):\n",
    "    DEprot = mostDiffProt[0][i]\n",
    "    Features[\"Protein \"+DEprot[0]] = overlap_protein_data[DEprot]\n",
    "    DEgene = mostDiffGene[0][i]\n",
    "    Features[\"Expression of \"+DEgene[0]] = overlap_rna_data[DEgene]\n",
    "target = np.array(overlap_clinical_data[\"tumor_stage_pathological\"])\n",
    "encode_dict = {'Stage I':[1,0,0,0], 'Stage II':[0,1,0,0], 'Stage III':[0,0,1,0], 'Stage IV':[0,0,0,1]}\n",
    "encode_dict_alt = {'Stage I':0, 'Stage II':1, 'Stage III':2, 'Stage IV':3}\n",
    "\n",
    "#One hot, though ordinal probably would have worked. This allows the model to not expect a \n",
    "#pattern 1 to 2, 2 to 3, etc. Probably not necessary.\n",
    "y = np.array([encode_dict[stage] for stage in target])\n",
    "y_alt = np.array([encode_dict[stage] for stage in target])\n",
    "X = np.array(Features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "2ea7d227-c31b-44f3-a672-8f8603177da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8037878787878789 percent average accuracy with KNeighbors Classifier\n",
      "0.7242424242424242 percent average accuracy with DecisionTree Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ME\\anaconda3\\envs\\qbio_490_dgmarsha\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ME\\anaconda3\\envs\\qbio_490_dgmarsha\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ME\\anaconda3\\envs\\qbio_490_dgmarsha\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ME\\anaconda3\\envs\\qbio_490_dgmarsha\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ME\\anaconda3\\envs\\qbio_490_dgmarsha\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ME\\anaconda3\\envs\\qbio_490_dgmarsha\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ME\\anaconda3\\envs\\qbio_490_dgmarsha\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ME\\anaconda3\\envs\\qbio_490_dgmarsha\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ME\\anaconda3\\envs\\qbio_490_dgmarsha\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ME\\anaconda3\\envs\\qbio_490_dgmarsha\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7999999999999999 percent average accuracy with MLP Classifier\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (77, 4) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[311], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m     22\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,stratify\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m---> 23\u001b[0m     \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict(X_test) \u001b[38;5;66;03m#Mind X,y are np.array, not pd.series.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     accuracy[i] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28msum\u001b[39m(y_pred \u001b[38;5;241m==\u001b[39m y_test) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_test))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qbio_490_dgmarsha\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qbio_490_dgmarsha\\lib\\site-packages\\sklearn\\naive_bayes.py:262\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    240\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Gaussian Naive Bayes according to X, y.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partial_fit(\n\u001b[0;32m    264\u001b[0m         X, y, np\u001b[38;5;241m.\u001b[39munique(y), _refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight\n\u001b[0;32m    265\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qbio_490_dgmarsha\\lib\\site-packages\\sklearn\\base.py:606\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m--> 606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_separately:\n\u001b[0;32m    609\u001b[0m         \u001b[38;5;66;03m# We need this because some estimators validate X and y\u001b[39;00m\n\u001b[0;32m    610\u001b[0m         \u001b[38;5;66;03m# separately, and in general, separately calling check_array()\u001b[39;00m\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;66;03m# on X and y isn't equivalent to just calling check_X_y()\u001b[39;00m\n\u001b[0;32m    612\u001b[0m         \u001b[38;5;66;03m# :(\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qbio_490_dgmarsha\\lib\\site-packages\\sklearn\\utils\\validation.py:1184\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1183\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m-> 1184\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m     _assert_all_finite(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39mestimator_name)\n\u001b[0;32m   1186\u001b[0m     _ensure_no_complex_data(y)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\qbio_490_dgmarsha\\lib\\site-packages\\sklearn\\utils\\validation.py:1245\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1234\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1235\u001b[0m             (\n\u001b[0;32m   1236\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1241\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1242\u001b[0m         )\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m-> 1245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[0;32m   1247\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (77, 4) instead."
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    \"KNeighbors Classifier\":KNeighborsClassifier(), \"DecisionTree Classifier\":DecisionTreeClassifier(),\n",
    "    \"MLP Classifier\":MLPClassifier(solver = 'lbfgs'), \"GaussianNB\":GaussianNB()}\n",
    "#That solver is supposed to be better for small datasets, and it stops the convergence warnings.\n",
    "\n",
    "for classi in classifiers.keys(): \n",
    "    classifier = classifiers[classi]\n",
    "    accuracy = [-1]*10\n",
    "    for i in range(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7,stratify=y)\n",
    "        if(classi == \"GaussianNB\"):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y_alt, train_size=0.7,stratify=y_alt)\n",
    "        #The Gaussian classifier can't seem to handle the one-hot encoded target.\n",
    "        #The others all perform better with it, so I am doing it that way for them.\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test) #Mind X,y are np.array, not pd.series.\n",
    "        accuracy[i] = (sum(y_pred == y_test) / len(y_test))\n",
    "    print(np.mean(accuracy),\"percent average accuracy with \"+classi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a35e9b93-47e7-424f-baf6-924b4326ceed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I don't know the accuracy of the Gaussian model, but of the three I was able to do, \n",
    "#KNeighbor was the best.\n",
    "#If you run this code, it should work, allowing you to see if the last model would have\n",
    "#taken the top spot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
